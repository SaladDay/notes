### 模型(参数)选择与调优



#### 1. 交叉验证(Cross Validation)

> 我们之前讲数据分为训练集和测试集，但是由于测试集的固定，不免会出现特殊情况，因此我们需要一个合适的方法来测试评估获取模型的真实性能。

##### 1.1 k折交叉验证

将训练集分为K份，每次选取一个子集作为测试集，其余作为训练集，然后重复K次，每次可以获得一个准确率，平均即可获得更准确的准确率。

目的：得到更准确的模型评估数据。





#### 2. 超参数搜索--网格搜索(Grid Search)

##### 2.1 介绍

> 通常情况下，有很多参数是需要手动设置的(如KNN算法中的K值)，这种叫做超参数。
>
> 不同的参数训练出的模型准确率不同，为了获取最优的模型，我们需要遍历参数。
>
> 这种方式便称为网格搜索(暴力搜索)

##### 2.1 API

```python
# 在Sklearn中，GridSearchCV是用来网格搜索，并且对每个参数的结果都CV(交叉验证)的APi
sklearn.model_selection.GridSearchCV(estimator,param_grid=None,cv=Node)
 - 对估计器的指定参数值进行暴力搜索
 - estimator 估计器对象
 - param_grid 估计器参数
 - cv 指定几折交叉验证
 
 结果参数：
 - 最佳参数：best_params_
 - 最佳结果: best_score_
 - 最佳估计器: best_estimator_
 - 交叉验证结果: cv_results_
```

##### 2.2 实例

我们对鸢尾花数据集的KNN算法进行优化。

![image-20230224175214541](https://saladday-figure-bed.oss-cn-chengdu.aliyuncs.com/img/image-20230224175214541.png)







