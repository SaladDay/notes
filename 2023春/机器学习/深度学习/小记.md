- 似然：

> 现实下已经发生了这件事，他在理论世界中对应某个A模型的可能性 叫做A模型的似然值。

- 极大似然估计

> 硬币既然投出了这个结果，那这个硬币本来的模型应该是怎么样的呢？
>
> 我们选择具有最大似然值的模型作为其模型的估计。
>
> > 在深度学习中，事实上就是去（通过一个一个已经发生的样本）计算神经网络中各个模型的似然值。得到具有极大似然值的模型，那么这个模型就是和现实情况的模型是最相似的。
>
> **最小化LOSS 等于最大化似然 **



- 交叉熵Cross Entropy

  ​	$$H(p,q)=-\sum{p(x)log\,q(x)}$$

  - 交叉熵越小，两个概率模型越逼近。
  - 用真实值(一般都是离散的01)做base计算交叉熵，可以计算预测模型和真实模型的相似程度。

- B(Binary)CEloss   Vs.   CrossEntropyLosss

  - 二分类Vs.多分类(单输出( possibility of belonging the type)Vs. 多输出(possibility of belonging this type ) )
  - 概率化过程: sigmoid Vs. softmax 

- 矩可以精确的知道两个概率模型是否一致
  - 但是 如果是想知道输出结果的误差，然而两个概率模型不一致，用矩就很难给出定量的表达
  - 交叉熵无论概率模型是什么样的，都可以给出误差的定量的表达