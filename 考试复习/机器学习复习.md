

> By saladday，考试较简单，通过此资料复习后可得满绩。



### 第一章 绪论

1. ==假设空间==hypothesis space指的是 可能的解决方案或模型的集合。假设空间的具体形式取决于所使用的机器学习算法和问题的性质。在监督学习中，假设空间通常由参数化模型表示，例如线性回归、决策树、神经网络等，每个模型都可以有一组参数来表示。

   在假设空间中，每一个可能的假设代表了一个可能的解决方案或模型，学习的目标是尽可能的让这个解决方案或模型fit训练集。

   在我们现在没有学习任何机器学习算法的时候，假设空间就是一组框框，标志着什么特征的选择是”好瓜“。

   

2. 而通常会有多个解决方案或模型fit训练集，这些fit训练集的解决方案或模型的集合便称为==版本空间==。

   **版本空间是假设空间中与训练数据一致的假设子集。**

   如何去挑选一个更好的模型呢？这就需要归纳（学习或者说是选择具体模型）的过程有一定的==归纳偏好==。

   1. 这里需要注意一个东西，学习算法（模型）的选择也是一种归纳偏好，其直接决定了学习器能否取得好的性能。
   2. 奥卡姆剃刀：简单的更好。这是基本原则。
   3. 没有免费午餐定理：一个模型在这里好不代表他到另外的地方依旧好

### 第二章 模型的评估与选择

1. 评估方法：

   我们通常使用测试集上的“测试误差”来近似泛化误差，因此我们需要尽可能保证测试集和训练集互斥（训练集出现过的在测试集不出现）

   下面是几种常见的分割方法：

   1. 留出法
      - 直接将数据集划分为两个互斥集合
      - 尽量不改变数据的原始分布
   2. 交叉验证法
      - 将数据集分层采样划分为k个大小相似的互斥子集，每次用k-1个子集的 并集作为训练集，余下的子集作为测试集，最终返回k个测试结果的君 子，k最常用的取值是10
   3. 自助法Bootstrap
      - 对数据集*D* ==有放回==采样 *m* 次 得到训练集*D’*,用*D\D’* 做测试集。
      - 由于改变了数据的分布，有可能引入误差，尽可能只在数据量很小的情况下使用。

2. 性能度量

   1. 回归任务往往使用均方误差MSE

   2. 分类任务一般使用错误率和精度（分对样本占样本总数的比例）

   3. 其他性能指标，在不同情况下会不同的用到
      1. 查全率：查的全不全，正例有没有全部被预测出来

      2. 查准率：查的准不准，预测出来是正例中的真正例的比率

      3. 统计真实标记和预测结果的组合可以得到“混淆矩阵”，根据混淆矩阵的结果可以画出P-R曲线。平衡点是曲线上“查准率=查全率”（==因为我想要两者都高==）时的取值，可用来用于度量P-R曲线有交叉的分类器性能高低。

         - P-R曲线绘制步骤：

           - 原始数据：

           - 

           - | 样本 | 预测概率 | 真实标签 |
             | ---- | -------- | -------- |
             | 1    | 0.8      | 正例     |
             | 2    | 0.6      | 正例     |
             | 3    | 0.3      | 负例     |
             | 4    | 0.2      | 正例     |
             | 5    | 0.7      | 负例     |

             根据不同阈值划分“预测的标签”：

             | 阈值 | 精确率 | 召回率 |
             | ---- | ------ | ------ |
             | 0.2  | 0.4    | 1.0    |
             | 0.3  | 0.5    | 0.67   |
             | 0.6  | 0.67   | 0.67   |
             | 0.7  | 0.5    | 0.33   |
             | 0.8  | 0.67   | 0.33   |

           - 以精确率和召回率为坐标画图。

      4. F1度量（比P-R曲线更常用）（是PR的调和平均）：

         ![image-20230603152617796](https://saladday-figure-bed.oss-cn-chengdu.aliyuncs.com/img/image-20230603152617796.png)

      5. ROC和AUC

         - 与P-R曲线很类似，只不过把横纵坐标的P-R改为了TPR（真正例率），FPR（假正例率）。
         - 绘制过程也一模一样。
         - AUC是ROC曲线下的面积，用来衡量二分类模型的性能。

      > ROC曲线关注的主要是模型对正例和负例的判别能力；
      >
      > PR曲线关注的是模型在正例中的准确率和召回率之间的权衡；
      
      1. 代价敏感错误率和代价曲线
      
         - 在现实情况下，不同类型的错误所造成的后果很可能不同。
         - 代价敏感错误率：![image-20230603153140990](https://saladday-figure-bed.oss-cn-chengdu.aliyuncs.com/img/image-20230603153140990.png)
         - 代价曲线：在非均等代价中，ROC曲线不能直接反映出模型的性能，而代价曲线可以。
           - 画法基本相同，还是不同阈值为不同的点。其中纵坐标改为代价（需要计算而来）。横坐标可以是准确率或者是召回率等等。

3. 比较检验看不懂，好像是用统计学的方式去比较两个模型的优劣

4. 偏差和方差，在我看来，偏差就是模型拟合训练集的能力，方差就是模型拟合测试集的能力。噪声是数据集本身的错误，对特征的辨别造成了干扰，是学习问题本身的难度。（因为一个理想的问题在训练集和测试集上反映的规律应该是完全一致的，而噪声导致这个规律有所偏差）

   - 偏差（bias）是模型对简化假设的倾向。高偏差模型往往对训练集和测试集的表现都不好，无法很好的捕捉复杂关系。在这种情况下，表现为欠拟合。
   - 方差（Variance）是指模型对训练集上的小波动过度敏感的倾向。高方差模型在训练集往往表现很好，但是对于未见过的数据则表现很差（决策树就是一种典型的高方差模型）。这种情况下，模型过度适应训练集的噪声和随机变动，即过拟合。


### 第三章 线性模型

1. 线性回归：

   - 目标：学得一个线性模型以尽可能准确地预测实值输出标记
   - 模型求解：基于最小化MSE来进行模型求解的方法叫做==最小二乘法==。

   $$
   w^\star,b^\star = \underset{(w,b)}{\arg\min} \sum_{i=1}^{m}(f(x_i)-y_i)^2
   $$

   - 在线性回归中，最小二乘法就是试图找到一条直线，使得所有样本到直线上的欧氏距离之和最小。

   - 这里涉及到一个问题，由于线性回归的损失函数比较简单，是可以由直接求导得到解析解的，不管是一个特征或者是多个特征，只要对不同的w，b进行求导即可。但是如果矩阵的转置乘以自身不可逆（奇异矩阵），则这个参数没有解析解，就要用数值优化方法（梯度下降等）来逼近解。
     
     - 解析解的公式：
       $$
       \hat{w}^\star = (X^TX)^{-1}X^Ty,其中\hat{w}=(w;b)
       $$
       
     - 需要强调的是，在实际情况下，有些时候我们即使存在解析解，我们依然会使用梯度下降（计算快，受限少，通用）。
   
2. 逻辑回归：

   - 一种线性分类模型，使用一个线性函数将输入特征的加权和映射到一个概率值。通常使用逻辑函数（如Sigmoid函数）对线性加权和进行非线性变换，将结果限制在0到1之间，表示样本属于某个类别的概率。

   - 注意，在处理二分类问题的时候，其与单层感知机（神经元）几乎一致。

   - 损失函数：使用交叉熵，度量逻辑回归模型的预测值与实际标签之间的差异。
     $$
     L(p, y) = -y * log(p) - (1-y) * log(1-p)
     $$
     

3. 线性判别分析：

   - 是一种经典的监督学习算法，用于降维和分类问题。它通过对数据进行线性变换，将高维特征映射到低维空间，同时最大化类别间的可分性。
   - 给定训练集，将样例都投影到一个直线（超平面），使得同类尽可能近，不同类尽可能远。在数学上，可以让同类样例投影点的协方差尽可能的小，而使得不同类的投影点的协方差尽可能的大，同时考虑二者即可得到欲最大化的目标。
   - 优化方法：一般是用矩阵论、广义瑞利商来进行，其实也可以用梯度下降

4. 多分类学习

   我们可以将二分类学习器改造成多分类学习器，但这个其实就很像神经网络了。一般来说，我们用的多的还是将二分类学习器集成来实现多分类学习。常见的策略OvO,OvR,MvM。

   ![image-20230603163811562](https://saladday-figure-bed.oss-cn-chengdu.aliyuncs.com/img/image-20230603163811562.png)

   1. OvO：

      比较简单，两两组合，最后投票生成预测值。

   2. OvR：

      也比较简单，每次将一个作为正例；Rest作为负例。看哪个分类器预测为正例，则预测结果为其。

      如果所有二分类学习器都分为反例的话，一般是拒绝分类；

      如果有多个二分类学习器分为正例的话，一般是选择最高置信度的。

   3. MvM：

      有点难。其主要的思想是，将多个分类目标进行二进制编码，对编码的每一位进行预测。

      采用“距离”的概念来判断最终的预测结果，每一个类别根据其每一位可以得到一个“海明距离、欧氏距离”，而我们可以看输入样例距离哪个最近来选择最终的预测。

      - ECOC编码对分类器错误有一定容忍和修正能力，编码越长、纠错能力越强
      - 对同等长度的编码，理论上来说，任意两个类别之间的编码距离越远，则纠错能力越强

5. 欠采样和过采样（再缩放）

   - 欠采样很好理解，少拿点呗。但EasyEnsemble的做法是不浪费样本，将正例（多类例）分为多份，使得每一份的数量和反例相当，然后从反例中Bootstrap，然后组成一份，用这一份训练一个基分类器，最后投票表决。
   - 过采样的话，基本方法：
     - 1.重复采样；
     - 2.插值法，先锁定一个正例（少的那个），然后基于欧氏距离找到附近最近的一个点，然后在两个点之间随机采样一个点。





### 第四章 决策树

> 决策树是一种强方差模型，我们需要时时刻刻注意过拟合问题

1. 在建树的时候，有三种情况需要返回：

   1. **纯度达标**，当前节点包含样本全部属于一个类别
   2. **达到预设的最大深度**
   3. **节点包含的样本数目小于预设阈值**，会选择最多的，然后自己变成叶子结点

2. 划分选择

   我们希望决策树的分支节点所包含的样本尽可能属于同一类别，即“纯度”越来越高，划分选择往往有以下几种方式：

   1. 信息增益

      基于信息熵，$Ent(D) = -\sum^{|y|}_{k=1}p_klog_2p_k(假定当前样本集合D中的第k类样本所占的比例为p_k)$,信息增益就是信息熵的增益

      **信息熵是信息的混乱程度（越小越稳定），因此只需要关注标签即可**

   2. 增益率

      假设我们把编号也作为候选划分属性，我们会发现编号的信息增益为0.998，原因很显然，编号将每一个样本都分为了一个组，每一组的信息熵为0。

      因此提出了增益率，加入了一个分母来偏好取值较少的特征。

   3. 基尼系数
      $$
      Gini(D) = \sum_{k=1}^{|y|}\sum_{k'!=k}p_kp_{k'}
      $$
      直观来说，基尼系数就是随机在集合中取两个，两个不是一个类的期望。Gini越小说明其不是一个类的概率越小，说明越纯净。（信息熵也是越小越纯净）

   ----

   这里给一个基于信息熵构建决策树的例子：

   假设我们有一个二分类问题，要根据两个特征 "年龄" 和 "收入" 来预测一个人是否会购买某个产品。我们的训练集如下：
   样本   年龄    收入    购买
   1      青年    高      是
   2      青年    低      是
   3      中年    低      是
   4      老年    低      否
   5      老年    高      否

   首先，计算原始数据集的信息熵。在这个例子中，样本总数为5，其中2个样本属于"是"类别，3个样本属于"否"类别。因此，原始数据集的信息熵为：
   $$
   H(D) = -3/5*log_2(3/5)-2/5*log_2(2/5)=0.971
   $$


   接下来，我们计算每个特征的信息增益，并选择具有最大信息增益的特征作为根节点。首先，计算特征 "年龄" 的信息增益：

   - 当 "年龄" 为 "青年" 时，有2个样本属于"是"类别，没有样本属于"否"类别。因此,$H(D_{{青年}}) = 0$
   - 当 "年龄" 为 "中年" 时，有1个样本属于"是"类别，1个样本属于"否"类别。因此，$H(D_{{中年}}) = 1$
   - 当 "年龄" 为 "老年" 时，有0个样本属于"是"类别，2个样本属于"否"类别。因此，$H(D_{{老年}}) = 0$

   因此，“年龄”特征的信息增益为：
$$
   Gain(D,年龄)=  H(D) - (2/5*0+1/5*1+2/5*0)=0.171
$$
   同样方法计算其他两个特征的。

----

3. 剪枝处理

   此时引入了一个东西叫做“验证集”，他与测试集的区别主要是，测试集在训练的全程对于学习器来说是不可见的。而验证集的作用是辅助训练。

   1. 预剪枝（**其实就是在划分每一个节点的时候通过验证集判断一下精度是否提升，从而决定是否要划分**）

   在广义来说，最大深度限制、最小样本数限制、类别纯度限制、最小信息增益限制都是预剪枝的一种，书上说的是基于验证集的预剪枝，其实也就是在验证集上看看，如果划分了精度反而下降的话，那就不分了。

   好处是其可以提早结束建树，减小训练开销，也可以避免过拟合。坏处是这是一种贪心策略，会过早挺早划分，有些时候后续的划分可能会大大的提高精度，但都被舍弃了。

   2. 后剪枝（**自底而上进行剪枝**）

   先建树，建树结束以后再自底而上剪枝。策略和预剪枝差不多，也是对比验证集，精度有提升就合并。

   好处是泛化性能往往优于预剪枝决策树、最大限度地利用训练数据，达到的是全局最优解。坏处很明显，需要先建树，计算开销大。

4. 连续值处理

   把连续值排序，==两两取中间值==作为候选分割点。

   采用离散属性值方法，选取最优分割点使得信息增益最大。

   注意：与离散属性不同，若当前结点划分属性为连续属性，该属性还可作为其后代结点的划分属性。

   > 还有一种方法叫做离散桶化，将一个区间的连续值作为离散值处理

3. 缺失值处理

   一般缺失值的处理方式1.去除样本2.去除特征3.众数填补4.平均值填补。

   但是这种方式在样本数少的情况下都不大合适。

   为了尽可能全面的利用数据，我们采取的是“人人有份“的方式。

   在寻找最优特征的时候我们不考虑缺失值。

   在分流数据的时候，正常值正常分；对于缺失值，我们按照不同分支（所分到的）样本数将其乘不同的权重进行分割，然后分给各个节点。

4. 多变量决策树

   很好理解，单变量就是一个框框（非叶子节点）使用一个特征来划分；多变量就是使用多个特征来划分。具体实现我猜应该是递归。

### 第五章 神经网络

由于本人对此块比较熟悉，就不展开复习了。





### 第六章 支持向量机

数学推导比较繁琐。

- 支持向量：支持或支撑平面上把两类类别划分开来的超平面的向量点。

- 正则化：也称为惩罚项。可以避免模型过度拟合训练集特征，控制模型复杂度，提高泛化能力

- 支持向量回归：与线性回归不同，其可以容忍一个范围的误差，在这个小范围内的损失都为0。

- 核方法：其实支持向量机最大的功劳就是提出了核方法，这是一种很普遍的处理非线性问题的方法。

  我们很清楚的知道，通过映射可以将低维空间映射到高维空间。而寻找具体的映射来使得其在高维空间线性可分是一件几乎不可能完成的事情（因为高维空间的维度非常大，映射函数的选择空间非常广，很难穷尽所有可能的映射），核函数可以看作是隐式映射函数的内积形式，提供了一种方式来间接计算样本在高维特征空间中的内积，而无需显式计算高维特征空间的表示，这样我们无需知道具体的核函数，即可完成我们最优化的目标。

  核方法有很多地方的应用，在LDA，PCA，聚类中都有应用。（基本上都是一些需要将样本分离的地方）

#### 问题：

1. 核函数为什么是有效的？
   - 核函数本身是非线性映射的内积形式，其可以隐式得将数据从原始空间映射到更高维度的特征空间，使得原本线性不可分的数据在新的特征空间中变得线性可分的性质。
   - 同时使用核函数可以避免直接在高维空间进行计算，避免维度灾难（计算和内存问题），这种方法我们称为核技巧。

### 第七章 贝叶斯分类器

这是一种基于贝叶斯定理的机器学习方法。

首先介绍一下相关的几个概念：

- 先验：根据若干年的统计（经验）或者气候（常识），某地方下雨的概率；机器学习中一般指的是训练集中的Label的概率。
- 后验：根据天上有乌云（原因或者证据/观察数据），下雨（结果）的概率；机器学习中一般是需要求的东西（知道一系列特征，求其属于某某类别的概率）
- 似然：下雨（果）的时候有乌云（因/证据/观察的数据）的概率，即已经有了果，对证据发生的可能性描述；
  - 这可能有点难理解--》label的条件概率即为似然

其次我想说明一下朴素贝叶斯分类器和其他分类器的区别：朴素贝叶斯分类器本身是没有需要学习的参数的，其训练的阶段与其他的分类器不同，其并非一个最优化的问题，其在训练的过程只需要根据训练的样本统计先验概率和条件概率（似然）即可。贝叶斯分类器更像是一种统计方法，只是用机器来辅助运算。

1. 朴素贝叶斯分类器

   所谓朴素，指的是假定所有输入事件之间是相互独立。

   我们可以知道原始的公式如下:
   $$
   P(y|X)=\frac{P(y)\,P(X|y)}{P(X)}
   $$
   注意，此时我们处于的是预测的情况，因此先验和似然均已知。

   ---

   - 那么在训练的时候我们就得计算先验和似然：
     - 先验：$P(c)=\frac{|D_c|}{|D|}$
     - 似然：
       - 离散：$P(x_i|c)=\frac{D_{c,x_i}}{D_c}$
       - 连续：$P(x_i|c) = \frac{1}{\sqrt{2\pi}\sigma_{c,i}}exp(-\frac{(x_i-μ_{c,i})^2}{2\sigma_{c,i}^2})$,$其中μ_{c,i}和\sigma_{c,i}分别是第c类样本在第i个属性上取值的均值和方差$

   ---

   那么！！P(X)即为一个常数，你甚至可以将其看为1。

   所以，公式为：
   $$
   P(y|X)\propto {P(y)\,P(X|y)}
   $$
   我们只需要求得：
   $$
   \begin{aligned}
           \hat{y} &=  argmax_y\,P(y|x) \\
           &=argmax_y\,P(y)P(X|y) \\
           &=argmax_y\,P(y)\prod_{i=1}^mP(x_i|y)
       \end{aligned}
   $$

   - P(y)--->先验概率
   - $\prod_{i=1}^mP(x_i|y)$--->似然

   此时我们先验和似然均为已知，我们只需要依次计算即可。

2. 朴素贝叶斯分类器的问题及改进

   ![image-20230604164345177](https://saladday-figure-bed.oss-cn-chengdu.aliyuncs.com/img/image-20230604164345177.png)

   在这个问题的背景下，P(敲声=清脆|好瓜=是)=0。这会导致似然等于0，而无论其他的特征多像好瓜，最后$P(y)\prod_{i=1}^mP(x_i|y)$均为0。

   此时我们便需要引入“拉普拉斯修正”：

   （一般来说，先验概率也需要进行拉普拉斯修正，但是我不能理解，你训练集都没有这个类别的数据你咋训练...）
   $$
   \begin{equation}
   \begin{aligned}
       P(c)&=\frac{|D_c|+1}{|D|+N} \\
       P(x_i|c)&=\frac{|D_{c,x_i}|+1}{|D_c|+N_c}
   \end{aligned}
   \end{equation}
   $$
   其中，N为类别数，D为总的样本数，$D_c$为c类别的样本数。$N_i$为第i个属性可能的取值数，$D_{c,x_i}$为类别为c且第i个属性为$x_i$的样本数。

   这个修正在训练数据量大了以后影响基本上就可以忽略了。

3. 半朴素贝叶斯分类器：

   没搞懂，不会。

4. 贝叶斯网：

   没搞懂，不会。

5. EM算法(期望最大化算法)：

   其实EM算法大多用于无监督学习（可以看作是Label作为隐变量）。

   大致介绍一下。假设我只知道一堆的成绩，而不知道哪些是哪个班级的，我需要将其分为两个班级。首先，我假设两者服从高斯分布，同时猜一下两个班级成绩的分布参数（这是E步骤）；其次，我通过极大似然可以得到每个成绩属于不同班级的可能性（其实也就是隐变量的分类可能性），此时我们再通过已经带有可能性标签的数据重新校准分布参数（这是M步骤）。重复迭代，直至参数收敛。

   将他运用到贝叶斯分类器上实际上是为了解决缺失值的问题：

   当我们训练数据存在缺失值的情况，某些先验概率和似然其实是无法进行计算的。

   而在这里先验概率和似然可以看做是朴素贝叶斯分类器的“模型参数”。

   

   1. 初始化：给出模型参数的初始值，包括西瓜为好瓜或坏瓜的先验概率，以及在给定西瓜是好瓜或坏瓜的条件下，根蒂特征和其他特征的条件概率。能算的就算，不能算的就瞎猜。

   2. E步骤(期望步骤):在给定当前参数的情况下，根蒂特征可能的值的概率。（这里其实是把根蒂作为label）

   3. M步骤(最大化步骤):使用现有的特征数据和E步骤中计算出的根蒂特征的概率，来重新估计先验概率和似然（模型的参数）。

   4. 重复步骤2和步骤3，直到模型参数收敛。

      

   

### 第八章 集成学习

#### 引言：

- 集成学习是一种技术框架，其按照不同的思路来组合基础模型， 从而达到其利断金的目的。由于不再是单一的模型进行预测，所 以模型有了“集思广益”的能力，也就不容易产生过拟合现象
-  集成学习有两个主要的问题需要解决，第一是如何得到若干个 个体学习器，第二是如何选择一种结合策略，将这些个体学习器 集合成一个强学习器
- 目前来说，同质个体学习器的应用是最广泛的，一般常说的集 成学习的方法都是指的同质个体学习器
- 而同质个体学习器使用最多的模型是CART决策树和神经网络
- 同质个体学习器按照个体学习器之间是否存在依赖关系可以分为两类:
  - 第一种是个体之间存在强依赖关系，一系列的学习器都需要通过串行产生，代表算法为boosting系列
  - 第二种是个体之间不存在强依赖关系，一系列的学习器并行产生，代表算法为bagging系列
- 在基模型准确率都好于随机猜测的前提下，集成模型的准确率是与基模型的多样性成反比。

####  Boosting

1. 介绍：Boosting是一族可以将弱学习器提升为强学习器的算法。工作机制大致为：先从初始训练集中训练出一个基学习器，再根据基学习器的表现对训练样本分布进行调整，使得先前基学习器做错的训练样本在后续收到更多的关注，然后基于调整后的样本训练下一个基学习器；如此重复进行，知道基学习器的数目达到了事先指定的值T，最终再将这T个基学习器进行加权组合。

##### AdaBoost（Boosting族最出名的算法,仅针对于二分类问题）

其实算法很简单

![image-20230610022322972](https://saladday-figure-bed.oss-cn-chengdu.aliyuncs.com/img/image-20230610022322972.png)

1. 先将所有的权重固定为1

2. 再循环T次

   1. 使用带权重的样本进行训练
   2. 基于带权重的样本计算误差率
   3. 如果误差超过随机猜测就不要
   4. 否则计算出 a（是放入组合的权重）
   5. 调整下一步的样本权重（其中Z是归一化因子）

3. 最后将每一步训练得到的学习器组合即可

   <img src="https://saladday-figure-bed.oss-cn-chengdu.aliyuncs.com/img/image-20230610022558150.png" alt="image-20230610022558150" style="zoom:33%;" />

 		此处所谓的转化其实就是改了一下权重

#### Bagging

1. 介绍：欲得到泛化性能较好的集成模型，集成中的各个个体应该尽量独立，虽然”独立“在现实条件中无法做到，但可以设法使得基学习器之间有较大的差异。给定一个数据集，一种可能的做法是对训练样本进行采样，产生不同的子集，再对不同的子集进行训练出不同的基学习器。但是，如果采样出的样本都完全不同，每个基学习器都只用了一部分训练集数据，这样无法训练出较好的基学习器，为了解决这个问题，我们考虑使用相互有重叠的交叉采样。

2. Bagging（这个名字是由Bootstrap AGGregatING缩写而来的）。其具体做法很简单：给定包含m个样本的训练集，我们先随机取出一个样本放入采样集中，再把该样本放回（使得下次采样仍然可以被选中），这样经过m此采样，我们可以得到含m个样本的采样集。照这样，我们可以采样出T个含m个训练样本的采样集，然后基于每个采样集训练出一个基学习器。

   一般来说Bagging对分类进行投票，回归进行简单平均。



##### 随机森林RF（Bagging族中重要的算法）

- 首先为什么Bagging要与DT相结合？
  - Bagging获取到的各个子集之间相似度是较高的，因此我们需要一个高方差、易过拟合的模型，DT可以使用相似的数据集输出多样性的基学习器。
- RF是Bagging的一个拓展变体，RF在以决策树为基学习器构建集成的基础上，进一步在决策树的训练过程中加入了随机属性选择。
  - 对基学习器的每一个节点，先从该节点的属性集合中选择包含k个属性的子集，然后再从这个子集中选择最优属性进行划分。
  - 因此RF中的基学习器的多样性不仅来自样本扰动，而且来自属性扰动，这就使得最终集成的泛化性能可通过个体学习器的差异而进一步提升。



#### 结合策略：

##### 1.平均法：

- 简单平均法
- 加权平均法

##### 2.投票法

- 绝对多数投票法（某标记超过半数，否则拒绝预测）
- 相对多数投票法（预测最多的标记）
- 加权投票法

##### 3.学习法

学习法就是相当于将初级学习器的输出作为新的Feature来递交给次级学习器进行学习，最终输出一个y的预测。

Stacking（堆叠法）是一个著名的算法。

![image-20230610130943076](https://saladday-figure-bed.oss-cn-chengdu.aliyuncs.com/img/image-20230610130943076.png)

#### 多样性

- 误差-分歧分解 

- 多样性度量
- 多样性扰动



### 第九章 聚类

#### 1. 性能度量

> 目的：评估一个聚类的好坏
>
> 结论：”簇内相似度高，簇间相似度低“

有两类指标：

- 外部指标
- 内部指标

##### 1.1 外部指标

>  将聚类结果与某个 “参考模型” 进行比较，称为 “ 外部指标 ”。
>
> 这里我觉得很怪，明明是无监督学习，拿来的参考模型。算了，不管他了反正也不会去用

![](https://gavin-pic-1302578220.cos.ap-beijing.myqcloud.com/img/20210209195423.png)

![](https://gavin-pic-1302578220.cos.ap-beijing.myqcloud.com/img/20210209194620.png)

![](https://gavin-pic-1302578220.cos.ap-beijing.myqcloud.com/img/20210209194628.png)

![](https://gavin-pic-1302578220.cos.ap-beijing.myqcloud.com/img/20210209194608.png)

<img src="https://gavin-pic-1302578220.cos.ap-beijing.myqcloud.com/img/20210209194658.png"  />

##### 1.2 内部指标

> 直接考察聚类结果而不利用任何参考模型，称为 “ 内部指标 ”。
>
> 我认为这个是聚类任务常常使用的指标，可很清楚的反映出”簇内相似度高，簇间相似度低“的程度

![](https://gavin-pic-1302578220.cos.ap-beijing.myqcloud.com/img/20210209195511.png)

![](https://gavin-pic-1302578220.cos.ap-beijing.myqcloud.com/img/20210209194806.png)

![](https://gavin-pic-1302578220.cos.ap-beijing.myqcloud.com/img/20210209194829.png)

![](https://gavin-pic-1302578220.cos.ap-beijing.myqcloud.com/img/20210209195003.png)

注意：

- avg：簇内样本的平均距离
- diam：簇内样本的最大距离（直径）
- dmin：簇间样本的最小距离
- dcen：簇中心间距离

这几个指数就反映了”簇内相似度高，簇间相似度低“的程度，也就反映了聚类的性能

#### 2.距离计算

> 那么此时就有一个问题，dist（x1,x2）怎么计算，距离怎么定义？

##### 2.1 什么算是距离度量？

若它是一个 “ 距离度量 ”，则应该满足以下性质：

<img src="https://gavin-pic-1302578220.cos.ap-beijing.myqcloud.com/img/20210210004316.png" style=";" />

![](https://gavin-pic-1302578220.cos.ap-beijing.myqcloud.com/img/20210210004325.png)

直递性实际上就是两边之和大于第三边。

![](https://gavin-pic-1302578220.cos.ap-beijing.myqcloud.com/img/20210210015553.png)

##### 2.2 有序属性、无序属性分别应该怎么计算距离？

1. 有序属性

![](https://gavin-pic-1302578220.cos.ap-beijing.myqcloud.com/img/20210210004639.png)

还有一个叫做切比雪夫距离：

D(x, y) = max(|x₁ - y₁|, |x₂ - y₂|, ..., |xn - yn|)，意思其实就是XY向量在各个分量上差的绝对值的最大值。

2. 无序属性

> 我没去深究他是怎么来的，我觉得只要知道有这个东西就行了

![](https://gavin-pic-1302578220.cos.ap-beijing.myqcloud.com/img/20210210011512.png)

> 还有一个比较好理解的但是书上没有介绍，叫做”汉明距离“
>
> 其将每一个离散值进行二进制编码，对每一位计算距离来衡量两个离散属性之间的距离

3. 混合距离

将闵可夫斯基距离和VDM结合在一起即可处理混合属性了。

4. 加权距离

当样本空间中不同属性的重要程度不同的时候，我们就要使用加权距离进行处理。

#### 3. 原型聚类

> 此类算法先对原型进行初始化，然后对原型进行更新迭代求解。
>
> 采用不同的原型表示，不同的求解方式，将产生不同的算法

##### 3.1 K均值（注意不是K近邻，K近邻是分类）

步骤：

1. 随机选取样本作为初始均值向量（初始值：k 的值【即几个簇】）
2. 分别计算每个样本点到均值向量的距离，距离哪个近就属于哪个聚类
3. 通过2计算出来的划分，重新计算均值向量（中心点，直接平均出来）

最后结果得到的是数据点的划分。

##### 3.2 学习向量量化(LVQ)

> 其假设数据样本带有类别标签，学习过程利用样本的这些监督信息来辅助聚类

步骤：

1. 初始化随机选择样本作为原型向量（一般一个类选择一个）
2. 从数据集中随机选取一个样本x
3. 找出与x距离最近的原型向量
   1. 如果两者类别相同，原型向量向x靠近
   2. 如果两者类别不同，原型向量向x远离
4. 迭代直至收敛

最后结果得到的是一组原型向量，可通过垂直平分线来得到划分。

##### 3.3 高斯混合聚类

> 实际上是更复杂一点的聚类，利用了EM算法（期望最大化算法）

步骤：

1. 初始化高斯混合成分的个数为k，假设每一个高斯混合分布的参数α，μ以及协方差矩阵Σ
2. 分别计算每个点的后验概率
3. 通过每个点的后验概率重新计算α，μ，Σ
4. 重复3.4直至收敛

最后得到的结果是一组高斯分布的参数α，μ以及协方差矩阵Σ。

- 相比较而言，K均值用一个矩形（圆形）来分割样本，高斯混合聚类用高斯模型来分割，更复杂，适用于软分类（没有明确边界线）的情况。

#### 4.密度聚类

> 密度聚类算法从样本密度的角度来考察样本之间的可连接性，并基于可连接性不断拓展聚类簇以获得最终的聚类结果

![](https://gavin-pic-1302578220.cos.ap-beijing.myqcloud.com/img/20201018201435.png)

往往我们需要根据不同情况选择需要什么样的算法。

步骤：

1. 初始值：①邻域参数 ε（画圈圈的半径）     ② 最少点个数 MinPts （初始满足画圈圈要包含多少个点才可以开始）
2. 先找出核心对象集合（满足MinPts的集合）
3. 随机选择一个核心对象作为种子，找出他密度可达的所有样本，这就构成了一个簇C1。
4. 将C1中包含的核心对象从核心对象集合中去除
5. 重复2345直至核心对象集合为空

特点：

- 其可以忍受噪音样本



#### 5.层次聚类

> 层次聚类试图在不同层次上对数据集进行划分，从而形成树形的聚类结构。
>
> 如果要分成几个簇都不清楚的话，那层次聚类是一个很好的选择
>
> 一般我们采用自底向上的聚合策略。

<img src="https://saladday-figure-bed.oss-cn-chengdu.aliyuncs.com/img/image-20230610151801548.png" alt="image-20230610151801548" style="zoom:50%;" />

在不同的高度上划分，我们可以得到不同数量簇的聚类结果。

步骤：

1. 初始每个样本为一个簇
2. 两个最近聚类簇进行合并，该过程不断重复，直至只有一个簇。

关键在于如何计算两个簇之间的距离，提供了三种，分别是：最小距离，最大距离和平均距离。（三者各有其优点）

![](https://gavin-pic-1302578220.cos.ap-beijing.myqcloud.com/img/20210210025032.png)





### 题目

#### 1. 决策树连续值处理：

1. 二元切分
2. 分桶离散化

#### 2. 决策树缺失值处理：

1. 删除缺失值（包括去除样本和去除特征）
2. 填充缺失值（众数、平均数）
3. 特殊值标记
4. 使用估计模型（EM算法）
5. 分流*

#### 3.贝叶斯分类器连续值处理：

假设数据服从某种特定的概率分布。可以假设连续值特征服从某种已知的概率分布，如高斯分布（正态分布）。然后，可以使用训练数据估计出每个类别的特征在该分布下的参数，如均值和方差。对于新样本，计算其在每个类别下服从该概率分布的概率。



#### 4.贝叶斯分类器缺失值处理：

缺失值处理其实是差不多的。就是那四种方式。



#### 5.k-均值算法例题：

题目给出

1. 簇的数目k=2
2. 下表数据表（n=8）行数据

| 序号 | 属性1 | 属性2 |
| :--- | :---- | :---- |
| 1    | 1     | 1     |
| 2    | 2     | 1     |
| 3    | 1     | 2     |
| 4    | 2     | 2     |
| 5    | 4     | 3     |
| 6    | 5     | 3     |
| 7    | 4     | 4     |
| 8    | 5     | 4     |

解:

1. 第一次迭代：由于最终结果要为**k=2个簇**,所以第一次迭代先**随机找两行数据**，如第1行和第3行当为初始点，

   ①要将全部数据分为两个簇，运用欧氏距离，让2,4,5,6,7,8依次和1和3分别进行距离计算，然后比较，离1近则和1合并，离3近则和3合并，这次迭代得到两个簇{1,2}和{3,4,5,6,7,8}

   ②对产生的簇分别计算平均值，得到平均值点

   对于{1,2},属性1：(1+2)/2=1.5,属性2：(1+1)/2=1,则平均值点为(1.5,1)

   对于{3,4,5,6,7,8},属性1：(1+2+4+5+4+5)/6=3.5,属性2：(2+2+3+3+4+4)/6=3，则平均值点为(3.5,3)

2. 第二次迭代：再将表中全部数据按离平均值点(1.5,1)和(3.5,3)最近的原则，重新分配。得到两个新的簇：{1,2,3,4}和{5,6,7,8}；

   再重新计算簇平均值点，得到新的平均值为(1.5,1.5)和(4.5,3.5)

3. 第三次迭代：再将表中全部数据按离新的平均值点(1.5,1.5)和(4.5,4.5)最近的原则，重新分配。得到两个新的簇：{1,2,3,4}和{5,6,7,8}；这里发现与第二次迭代得到的两个簇相比,没有出现新的簇，则算法结束。

**最终的到两个簇{1,2,3,4}和{5,6,7,8}。**



#### 6.神经网络怎么解决过拟合的问题？

1. 正则化：在损失函数后面加上一项权重矩阵，因为梯度下降需要最小化损失函数，因此权重矩阵也会变小。在直观上理解其实就是减小了很多神经元的影响，那么大的复杂的网络就会被”消减“成一个较小的网络，从而避免过拟合的问题。
2. Dropout：训练过程中把一部分神经元丢弃
3. 提前停止
4. 对训练数据进行一系列随机变换或增强操作，以增强训练集的多样性

#### 7.半监督算法

由于标签传播还是有点难，我看了一个自学习算法(self-training):

- 收集所有标记和未标记的数据，但我们只使用标记的数据来训练我们的第一个监督模型。
- 利用该模型预测未标记数据的类别。
- 选择满足预定义标准的观测结果(例如，预测概率为>90%或属于预测概率最高的前10个观测结果)，并将这些伪标签与标记数据结合起来。
- 通过使用标签和伪标签来训练一个新的监督模型。然后我们再次进行预测，并将新观察结果添加到伪标记池中。
- 我们迭代这些步骤，当没有其他未标记的观测满足伪标记标准，或者达到指定的最大迭代次数时，迭代结束。

#### 8. 泛化误差是什么？

泛化误差是指机器学习模型在未见过的新数据上的预测性能。在模型训练过程中，我们通常使用训练数据来调整模型的参数，使其能够更好地拟合训练数据。然而，我们最终的目标是让模型在未见过的新数据上表现良好，而不仅仅是在训练数据上表现好。

在模型训练过程中，我们通过使用验证集来估计模型的泛化误差。通过监控验证误差，我们可以选择适当的模型复杂度和训练策略，以便在新数据上获得更好的泛化性能。

#### 9.Relu的优劣？

优势：

1. 非线性（必然）
2. 计算高效
3. 缓解梯度消失的问题，relu函数在输入大于0时具有恒定为1的梯度。在深层神经网络中不会因为越乘越小而产生梯度消失问题

劣势：

1. 死亡Relu：当输入小于等于零时，ReLU函数的输出为零。如果在训练过程中某个神经元的权重更新导致该神经元永远为负值，那么该神经元的梯度将一直为零，从而导致神经元“死亡”（即无法更新权重）。

#### 10.列举强方差模型

决策树，MLP，高阶多项式回归，支持向量机（特别是选择高斯核的时候）

